# CLAUDE.md ‚Äî Investigator üêäüîç

This file provides guidance to Claude Code (claude.ai/code) when working in this repository.

## Purpose

**Investigator** is a three-agent AI research pipeline. This repository stores completed investigations and the pipeline that produces them. The goal is purely to research, analyze, and synthesize understanding of topics ‚Äî never to solve problems, implement solutions, or draft pseudocode. Investigations produce findings and insights only.

## Orchestration Model

This repo operates on a three-layer agent pattern:

| Layer | Role |
|-------|------|
| **Main session (this session)** | Synthesizer & orchestrator ‚Äî never does raw research, protects its context window |
| **Investigation agents (spawned)** | One-shot researchers ‚Äî investigate a single topic and return structured outputs |
| **Validation agents (spawned)** | One-shot fact-checkers ‚Äî verify sources and findings after every investigation, always run last |

The main session spawns investigation agents using the persona in `templates/agent_persona.md`, then spawns a validation agent using the persona in `templates/validator_persona.md`. Raw research and raw validation never happen in the main session.

## Structure Convention

### Folder Naming

Investigation subfolders use **PascalCase** ‚Äî no hyphens, underscores, or spaces.

```
MsDefenderAwsExclusions/
LlmContextWindows/
RustAsyncPatterns/
AwsIamPrivilegeEscalation/
```

### Scope Gate (required before spawning any investigation agent)

Before spawning an investigation agent, the main session **must** ask the following scoping questions to ensure the investigation is focused enough to produce high-quality, atomic findings:

1. **What is the single core question?** ‚Äî Can it be stated in one sentence? If not, split it.
2. **What is out of scope?** ‚Äî Name at least one related area that will not be covered.
3. **Who is the intended consumer of the findings?** ‚Äî Planning LLM, human analyst, or both?
4. **Are there known sub-topics that warrant separate investigations?** ‚Äî If yes, create separate subfolders rather than one broad investigation.

A question like "tell me about cloud security" must be narrowed (e.g., "What are the documented IAM privilege escalation paths in AWS that do not require existing admin permissions?") before proceeding.

## Investigation Workflow

Each investigation subfolder must contain the following output files:

| File | Audience | Required |
|------|----------|---------|
| `investigation.md` | Engineers | Always |
| `investigation.json` | Agents | Always |
| `validation_report.md` | All | Always |
| `brief_leadership.md` | Engineering Leadership | Technical investigations only |
| `brief_po.md` | Product Owners / PMs / EMs | Technical investigations only |

**Technical investigations** (infra, security, configuration, operational risk) must include `audience_briefs` in `investigation.json` ‚Äî `brief_leadership.md` and `brief_po.md` are then generated by script.

**Non-technical investigations** (market events, financial analysis, historical research, organizational topics) omit `audience_briefs` entirely ‚Äî no brief files are generated. A PO should never receive a financial/market investigation as a brief; the full document is the artifact.

All markdown files are derived from `investigation.json` by script and must never be hand-edited. `validation_report.md` is always the final artifact.

### Step Order (mandatory)

1. **Scope gate** ‚Äî main session asks scoping questions, narrows the question
2. **Spawn investigation agent** ‚Äî writes `investigation.json`; runs `json_to_md.py` to generate `investigation.md` and brief/glossary files
3. **Spawn validation agent** ‚Äî receives `investigation.json` as structured input, writes `validation_report.md`
4. **Remediation** ‚Äî if validation finds `CONTRADICTED` or material `UNVERIFIED` findings, the main session re-spawns the investigation agent with the specific discrepancies noted, and the agent corrects only the affected sections and re-syncs `investigation.json`
5. **Main session synthesizes** across all investigation files

**Validation is never optional and never skipped.**

### Remediation Rules

| Verdict | Action |
|---------|--------|
| `CONTRADICTED` | Must be corrected ‚Äî re-spawn investigation agent with the specific claim and contradicting evidence |
| `UNVERIFIED` (material claim) | Must be corrected or downgraded to an open question |
| `UNVERIFIED` (minor / peripheral) | May be left as-is with a note in `open_questions` |
| `PARTIALLY CONFIRMED` | Investigator must narrow the claim to only what was confirmed |
| `DEAD` source | Must be replaced with an accessible equivalent or removed |
| `REDIRECT` source | Update URL in `investigation.json`, then re-run `json_to_md.py` to regenerate markdown |
| `OUT_OF_SYNC` | Re-run `json_to_md.py` to regenerate markdown from `investigation.json` ‚Äî never modify `investigation.json` to match the markdown |

After any correction, re-run `json_to_md.py` and confirm `check_sync.py` exits 0 before the workflow is considered complete.

### Actionable Insights First

Every investigation that has concrete outputs (paths, configs, commands, decisions, recommendations) **must** populate `quick_reference` in `investigation.json`. The generator renders this as the first section after the header ‚Äî before question, context, or findings.

The principle: a human opening the markdown should get the answer in the first scroll, and the evidence behind it below. If the investigation has no concrete actionable output, `quick_reference` may be omitted.

### Agent Input Convention

`investigation.json` is the machine-readable handoff format. When passing context to any downstream agent (validation, synthesis, follow-on investigation), always pass `investigation.json` as structured input ‚Äî not `investigation.md`. The JSON is authoritative for inter-agent communication.

### JSON is the only authored file ‚Äî markdown is generated

Investigation agents write **`investigation.json` only**. The markdown is always produced by script:

```
python3 scripts/json_to_md.py <investigation_dir>
```

This eliminates JSON/MD drift entirely ‚Äî the markdown is derived, never hand-authored.

### Sync verification

After generating the markdown, verify with:

```
python3 scripts/check_sync.py <investigation_dir>
```

- **Investigation agent**: write JSON ‚Üí run `json_to_md.py` ‚Üí run `check_sync.py` ‚Üí must exit 0 before returning
- **Validation agent**: run `check_sync.py` first, paste stdout into report. Zero tokens spent on comparison logic.

The sync check normalizes both files, hashes field contents, and reports per-field IN_SYNC / OUT_OF_SYNC status.

Exit codes: `0` = IN_SYNC, `1` = OUT_OF_SYNC (re-run `json_to_md.py`), `2` = error (bad JSON or missing file ‚Äî fix before continuing).

### Script Failure Paths

| Script | Exit | Meaning | Recovery |
|--------|------|---------|----------|
| `json_to_md.py` | 2 | Invalid JSON, missing required field, or I/O error | Fix the error in `investigation.json` and re-run |
| `check_sync.py` | 1 | Content has drifted or a brief file is missing | Re-run `json_to_md.py` to regenerate markdown |
| `check_sync.py` | 2 | Invalid JSON or missing file | Fix the underlying error before checking sync |

Investigation agents must not return until both scripts exit 0.

### Trust Boundary

`investigation.json` field values are rendered verbatim into markdown. Agent-produced content must be treated as potentially unsafe:

- Single-value fields (`headline`, bullets, list items, concept names) must not embed newlines ‚Äî they break blockquote and table rendering.
- Concept `name` values must not begin with `#` ‚Äî they render as headings in the glossary.
- Source `url` values must use `https://` or `http://` ‚Äî other schemes are silently dropped by the renderer.
- Markdown files are never hand-edited. Any correction goes into `investigation.json` and is regenerated by script.

### Output Sections (required in investigation.json)

1. **Question** ‚Äî the specific question being investigated
2. **Context** ‚Äî why this topic matters
3. **Key Findings** ‚Äî standalone, atomic insights
4. **Concepts & Entities** ‚Äî key terms, technologies, systems, or actors
5. **Tensions & Tradeoffs** ‚Äî competing forces or unresolved tensions
6. **Open Questions** ‚Äî what remains unknown
7. **Sources & References** ‚Äî all cited material

There are no build, lint, or test commands ‚Äî this is a research/notes repository, not a software project.
